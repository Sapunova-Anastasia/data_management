{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача на регуляризцию\n",
    "\n",
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество на валидации: 0.119\n",
      "Качество на обучении: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anac_new\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.97795e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_degrees(source_data: list, degree: int):\n",
    "    \"\"\"Функция, которая принимает на вход одномерный массив, а возвращает n-мерный\n",
    "    Для каждой степени от 1 до  degree возводим x в эту степень\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "          source_data**n for n in range(1, degree + 1)  \n",
    "    ]).T\n",
    "\n",
    "data = pd.read_csv('data/non_linear.csv', sep=',')\n",
    "data.head()\n",
    "\n",
    "degree = 8\n",
    "X = generate_degrees(data['x_train'], degree)\n",
    "y = data.y_train.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "model = Ridge(alpha=0).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(\"Качество на валидации: %.3f\" % mean_squared_error(y_valid, y_pred))\n",
    "print(\"Качество на обучении: %.3f\" % mean_squared_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "у класса *Ridge* в конструкторе есть параметр регуляризации - обучите регрессию при $\\alpha=0.01$. \n",
    "\n",
    "Как изменилась ошибка на обучении? Как изменилась ошибка на валидации? Удалось ли победить переобучение? Используйте степень полинома n=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При alpha=0:\n",
      "Качество на валидации: 0.125\n",
      "Качество на обучении: 0.051\n",
      "\n",
      "При alpha=0.01:\n",
      "Качество на валидации: 0.077\n",
      "Качество на обучении: 0.058\n",
      "\n",
      "\n",
      "Как изменилась ошибка на обучении? Было 0.125, стало 0.077, т.е. ошибка на обучении падает.\n",
      "Как изменилась ошибка на валидации? Было 0.051, стало 0.058, т.е. ошибка на валидации растет.\n",
      "Таким образом, модель переобучилась. Модель с alpha=0.01 хуже, чем модель с alpha=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anac_new\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=5.81468e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "degree = 12\n",
    "X = generate_degrees(data['x_train'], degree)\n",
    "y = data.y_train.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "model = Ridge(alpha=0).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(\"При alpha=0:\")\n",
    "print(\"Качество на валидации: %.3f\" % mean_squared_error(y_valid, y_pred))\n",
    "print(\"Качество на обучении: %.3f\" % mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nПри alpha=0.01:\")\n",
    "model = Ridge(alpha=0.01).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(\"Качество на валидации: %.3f\" % mean_squared_error(y_valid, y_pred))\n",
    "print(\"Качество на обучении: %.3f\" % mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\n\\nКак изменилась ошибка на обучении? Было 0.125, стало 0.077, т.е. ошибка на обучении падает.\")\n",
    "print(\"Как изменилась ошибка на валидации? Было 0.051, стало 0.058, т.е. ошибка на валидации растет.\")\n",
    "print(\"Таким образом, модель переобучилась. Модель с alpha=0.01 хуже, чем модель с alpha=0\")\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашняя работа: Lasso vs Ridge\n",
    "\n",
    "На данных из файла `data/non_linear.csv`\n",
    "* сгенерируйте данные до степени *degree = 8* включительно\n",
    "* обучите модель `sklearn.linear_model.Lasso` и модель `sklearn.linear_model.Ridge` на полученных данных\n",
    "* используйте коэффициент регуляризации $\\alpha=0.8$ для обеих моделей\n",
    "* постройте два столбчатых графика, на которых отобразите величину коэффициентов в для Ridge регрессии и Lasso регрессии виде столбиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример графиков для 3-й степени (просто для примера, у вас может по-другому выглядеть). Какой можно сделать в вывод по величине коэффициентов?:\n",
    "![coeff_example](img/coeff_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anac_new\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7134369621139327, tolerance: 0.0024481555784964045\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: [ 4.54261785e-01  3.41976833e-01  3.27582091e-02 -2.07134533e-01\n",
      "  3.63216320e-02  1.18194116e-02 -3.68031932e-03  2.63585521e-04]\n",
      "Lasso: [-0.00000000e+00 -0.00000000e+00 -1.08299601e-02 -9.52247249e-03\n",
      "  1.03490179e-03  1.87872250e-04  3.38785318e-06 -2.14838285e-06]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ ---\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "degree = 8\n",
    "X = generate_degrees(data['x_train'], degree)\n",
    "y = data.y_train.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "model_ridge = Ridge(alpha=0.8).fit(X_train, y_train)\n",
    "model_lasso = Lasso(alpha=0.8).fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge:\",model_ridge.coef_)\n",
    "print(\"Lasso:\",model_lasso.coef_)\n",
    "\n",
    "n = 9\n",
    "x1 = np.arange(1, n) - 0.2\n",
    "x2 = np.arange(1, n) + 0.2\n",
    "\n",
    "y1 = model_ridge.coef_\n",
    "y2 = model_lasso.coef_\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(8)    \n",
    "fig.set_figheight(8)\n",
    "ax.bar(x1, y1, width = 0.4, label = 'Ridge', zorder = 2, alpha=0.5)\n",
    "ax.bar(x2, y2, width = 0.4, label = 'Lasso', zorder = 2, alpha=0.5)\n",
    "plt.legend(loc='upper right', title='коэффициенты:')\n",
    "plt.show()\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашнее задание: пишем Ridge регрессию.\n",
    "\n",
    "Мы использовали реализацию Ridge регрессию из библиотеки sklearn. Для того, чтобы  прокачать навыки программирования и освежить в памяти, как перемножать матрицы в numpy, напишите код для вычисления коэффициентов полиномиальной регрессии (для степени *degree=8*) с регуляризацией по формуле\n",
    "$$\n",
    "\\overline{w} = \\left(X^TX + \\lambda E\\right)^{-1}X^T\\overline{y}\n",
    "$$\n",
    "\n",
    "Для примера можно ориентироваться на то, как была реализована аналитическая формула для линейной регрессии в модуле \"Линейная регрессия. Часть I\"\n",
    "\n",
    "Единичную матрицу $E$ можно получить с помощью функции https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html . Размерность матрицы $k\\times k$ (по количеству коэффициентов линейной регрессии). Напоминаю, что количество коэффициентов регрессии совпадает с количеством фичей регрессии, в задании будет $k=8$, т.к. генерим признаки для полинома восьмой степени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.13001041e+00  4.54261788e-01  3.41976835e-01  3.27582082e-02\n",
      " -2.07134531e-01  3.63216308e-02  1.18194120e-02 -3.68031937e-03\n",
      "  2.63585523e-04]\n"
     ]
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "from numpy.linalg import inv, norm\n",
    "import numpy as np\n",
    "\n",
    "def ridge_coef(X, y, lambd, intercept=True):\n",
    "    if (intercept):\n",
    "        n=X.shape[1]+1\n",
    "        H = np.ones((X.shape[0],n))\n",
    "        H[:,1:n] = X\n",
    "        E = np.zeros((H.shape[1],H.shape[1]))\n",
    "        E[1:H.shape[1],1:H.shape[1]] = np.identity(H.shape[1]-1, dtype=float)\n",
    "    else:\n",
    "        H=X\n",
    "        E=np.identity(H.shape[1], dtype=float)\n",
    "    HT = H.transpose() \n",
    "    w = np.dot(np.dot(inv(np.dot(HT,H)+lambd*E),HT),y)\n",
    "    return w\n",
    "\n",
    "w = ridge_coef(X_train, y_train, 0.8)\n",
    "\n",
    "print(w)\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашнее задание: подбираем шаг градиентного спуска \n",
    "\n",
    "Очевидно, что чем больше шаг градиентного спуска (параметр *eta0* класса *SGDRegressor*), тем быстрее мы придём к оптимальным значениям. Используя под выше, поиграйтесь с параметром *eta0* и добейтесь , чтобы градиентный спуск закончился быстрее, чем за 200 шагов.\n",
    "\n",
    "Сколько шагов у вас получилось? Какое качество *RMSE* у Вашего решения? Визуализируйте функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерации остановлены на шаге 191\n",
      "RMSE: 0.1318719273796403\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "# можно установить None для эксперимента\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# для регрессии\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('data/non_linear.csv', sep=',')\n",
    "data = data[(data.x_train > 1) & (data.x_train < 5)].copy()\n",
    "\n",
    "X = data['x_train'].values.reshape(-1, 1) # превращаем X из простого массива в вектор-столбец\n",
    "y = data['y_train'].values\n",
    "\n",
    "# разбиваем на трейн и валидацию\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "data.head()\n",
    "\n",
    "rand_state = 42\n",
    "\n",
    "sgd_regressor = SGDRegressor(\n",
    "    learning_rate='constant',\n",
    "    eta0=0.01,\n",
    "    fit_intercept=True,\n",
    "    random_state=rand_state\n",
    ")\n",
    "\n",
    "# инициализация весов случайным образом\n",
    "w_current = np.random.random(2)\n",
    "epsilon = 0.0001\n",
    "\n",
    "# изменения весов и ошибка на валидации\n",
    "weight_evolution, rmse_evolution = [], []\n",
    "\n",
    "for step in list(range(800)):\n",
    "    # шаг градиентного спуска\n",
    "    sgd_regressor = sgd_regressor.partial_fit(X_train, y_train)\n",
    "    # отслеживаем изменения весов\n",
    "    weight_evolution.append(\n",
    "        distance.euclidean(w_current, sgd_regressor.coef_)\n",
    "    )\n",
    "    # проверяем критерий остановки\n",
    "    if weight_evolution[-1] < epsilon:\n",
    "        print(\"Итерации остановлены на шаге %d\" % step); break\n",
    "    rmse_evolution.append(\n",
    "        mean_squared_error(y_valid, sgd_regressor.predict(X_valid))\n",
    "    )\n",
    "    # обновление весов регрессии\n",
    "    w_current = sgd_regressor.coef_.copy()\n",
    "    \n",
    "\n",
    "print(\"RMSE:\", mean_squared_error(y_valid, sgd_regressor.predict(X_valid)))\n",
    "plt.plot(range(step), rmse_evolution)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашнее задание: SGD на многомерных данных\n",
    "\n",
    "Примените градиентный спуск к задаче прогнозирования цен на недвижимость в Бостоне. Какого качества на валидации удалось достичь по r2-score? Сколько итераций  понадобилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерации остановлены на шаге 37\n",
      "Правильность на обучающем наборе: 0.73\n",
      "Правильность на тестовом наборе: 0.62\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "X = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "X_train_scale = sklearn.preprocessing.scale(X_train)\n",
    "X_test_scale = sklearn.preprocessing.scale(X_test)\n",
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "rand_state = 42\n",
    "\n",
    "sgd_regressor = SGDRegressor(\n",
    "    learning_rate='constant',\n",
    "    eta0=0.01,\n",
    "    fit_intercept=True,\n",
    "    random_state=rand_state\n",
    ")\n",
    "\n",
    "# инициализация весов случайным образом\n",
    "w_current = np.random.random(13)\n",
    "epsilon = 0.0001\n",
    "\n",
    "# изменения весов и ошибка на валидации\n",
    "weight_evolution, rmse_evolution = [], []\n",
    "\n",
    "for step in list(range(1000)):\n",
    "    # шаг градиентного спуска\n",
    "    sgd_regressor = sgd_regressor.partial_fit(X_train_scale, y_train)\n",
    "    # отслеживаем изменения весов\n",
    "    weight_evolution.append(\n",
    "        distance.euclidean(w_current, sgd_regressor.coef_)\n",
    "    )\n",
    "    # проверяем критерий остановки\n",
    "    # print(weight_evolution[-1])\n",
    "    if weight_evolution[-1] < epsilon:\n",
    "        print(\"Итерации остановлены на шаге %d\" % step); break\n",
    "    rmse_evolution.append(\n",
    "        mean_squared_error(y_test, sgd_regressor.predict(X_test_scale))\n",
    "    )\n",
    "    # обновление весов регрессии\n",
    "    w_current = sgd_regressor.coef_.copy()\n",
    "\n",
    "y_train_pred = sgd_regressor.predict(X_train_scale)\n",
    "y_test_pred = sgd_regressor.predict(X_test_scale)\n",
    "print(\"Правильность на обучающем наборе: {:.2f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Правильность на тестовом наборе: {:.2f}\".format(r2_score(y_test, y_test_pred)))\n",
    "\n",
    "    \n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашняя работа: добавляем регуляризацию в SGD\n",
    "\n",
    "В реализацию функции `gradient` добавьте параметр $\\lambda$, чтобы получить регуляризованный градиентный спуск\n",
    "\n",
    "Формула поменяется следующим образом:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{cc}\n",
    "\\frac{\\partial L}{\\partial w_0} = \\frac{2}{n}\\cdot(-1)\\cdot \\sum_{i=1}^{n} 1\\cdot \\left(y_i - \\sum_{j=1}^{m}w_jx_j^i + 2\\cdot 1\\right)&\\\\\n",
    "\\frac{\\partial L}{\\partial w_k} = \\frac{2}{n}\\cdot(-1)\\cdot \\sum_{i=1}^{n} x_k^i \\cdot\\left(y_i - \\sum_{j=1}^{m}w_jx_j^i + 2x_k\\right)& k\\neq 0 \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В этом модуле мы узнали, как  обучать линейную регрессию, не \"упираясь\" в аппаратные ресурсы: использовать градиентный спуск.\n",
    "Мы узнали, как детектировать переобучение модели и закрепили свои знания на примере полиномиальной регрессии и выяснили, как увеличить качество решения с помощью механизма регуляризации. Познакомились с двумя видами регуляризации -  Ridge и Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_train</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.182421</td>\n",
       "      <td>1.860341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.251605</td>\n",
       "      <td>1.878928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.270474</td>\n",
       "      <td>2.430015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.402553</td>\n",
       "      <td>2.327856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.427711</td>\n",
       "      <td>2.203649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_train   y_train\n",
       "5  1.182421  1.860341\n",
       "6  1.251605  1.878928\n",
       "7  1.270474  2.430015\n",
       "8  1.402553  2.327856\n",
       "9  1.427711  2.203649"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/non_linear.csv', sep=',')\n",
    "data = data[(data.x_train > 1) & (data.x_train < 5)].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алгоритм выполнился за следующее количество итераций: 22\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gradient(X, y, w, alpha=0) -> np.array:\n",
    "    # количество обучающих примеров в выборке\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    # считаем прогноз\n",
    "    y_hat = X.dot(w.T)\n",
    "    # вычисляем ошибку прогноза\n",
    "    error = y - y_hat\n",
    "    E = np.ones((n,m))\n",
    "    errors_with_alpha = np.multiply(E, error)+2*alpha*X\n",
    "    # дальше pointwise перемножение - умножаем каждую из координат на ошибку\n",
    "    pointwise_errors = np.multiply(X, errors_with_alpha) + X\n",
    "    # print(pointwise_errors.shape, X.shape, error.shape)\n",
    "    grad = pointwise_errors.sum(axis=0)*(-1.0)*2.0 / n\n",
    "   \n",
    "    return grad, error\n",
    "\n",
    "def eval_w_next(X, y, eta, w_current):\n",
    "    # вычисляем градиент\n",
    "    grad, error = gradient(X, y, w_current, 0.1)\n",
    "    # делаем шаг градиентного спуска\n",
    "    w_next = w_current - eta*grad\n",
    "    # проверяем условие сходимости\n",
    "    weight_evolution = distance.euclidean(w_current, w_next)\n",
    "    return (w_next, weight_evolution, grad)\n",
    "\n",
    "def gradient_descent(X: np.array, y: np.array, eta=0.01, epsilon=0.001) -> np.array:\n",
    "    m = X.shape[1] # количество фичей\n",
    "    # инициализируем рандомом веса\n",
    "    w = np.random.random(m).reshape(1, -1)\n",
    "    w_next, weight_evolution, grad = eval_w_next(X, y, eta, w)\n",
    "    step = 0\n",
    "    # повторяем до сходимости вектора весов\n",
    "    while weight_evolution > epsilon:\n",
    "        w = w_next\n",
    "        w_next, weight_evolution, grad = eval_w_next(X, y, eta, w)\n",
    "        step += 1\n",
    "        if step % 100 ==0:\n",
    "            print(\"step %s |w-w_next|=%.5f, grad=%s\" % (step, weight_evolution, grad))\n",
    "    print(\"Алгоритм выполнился за следующее количество итераций:\",step)\n",
    "    return w\n",
    "\n",
    "# трансформируем плоский массив X в вектор-столбец\n",
    "X = data['x_train'].values.reshape(-1, 1)\n",
    "n = X.shape[0]\n",
    "# добавляем тривиальный признак w_0, столбец из единиц. См. прошлый урок, почему так\n",
    "X = np.hstack([\n",
    "    np.ones(n).reshape(-1,1),\n",
    "    X\n",
    "])\n",
    "w = gradient_descent(X, data['y_train'].values.reshape(-1, 1), eta=0.008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: извлечение признаков из текста\n",
    "\n",
    "Реализуем пайплайн в виде функции, при помощи которой обработаем все текстовые описания. Для каждого описания\n",
    "* проводим токенизацию\n",
    "* удаляем пунктуацию\n",
    "* приводим к нижнему регистру\n",
    "* удаляем стоп-слова\n",
    "\n",
    "\n",
    "Примените процедуру токенизации к файлу brand_tweets_valid.csv\n",
    "\n",
    "Сколько уникальных токенов получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [wow, google, maps, mobile, v5, demo, sxsw, nice]\n",
      "1    [google, name, built, gettinng, stuff, trying,...\n",
      "2    [quot, apple, opening, temporary, store, austi...\n",
      "3    [tech, apple, opening, pop, store, austin, sxs...\n",
      "4              [gsdm, google, party, hook, sxsw, link]\n",
      "Name: tokenized, dtype: object\n",
      "Количество уникальных токенов: 1715\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "df = pd.read_csv('data/brand_tweets_valid.csv', sep=',', encoding='utf8')\n",
    "# удаляем строки, в которых отсутствует текст твита\n",
    "df.drop(df[df.tweet_text.isnull()].index, inplace=True)\n",
    "\n",
    "def tokenize_text(raw_text: str):\n",
    "    \"\"\"Функция для токенизации текста\n",
    "    \n",
    "    :param raw_text: исходная текстовая строка\n",
    "    \"\"\"\n",
    "    filtered_tokens = []\n",
    "    # -- ВАШ КОД ТУТ --\n",
    "    stop_words = [\n",
    "        'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
    "        'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
    "        'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
    "        'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "        'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
    "        'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
    "        'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
    "        'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
    "        'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
    "        'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'shold',\n",
    "        \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "        'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
    "        'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
    "        'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n",
    "    ]\n",
    "    \n",
    "    tokens = []\n",
    "    new_word = True\n",
    "    for symbol in raw_text:\n",
    "        if (symbol in string.punctuation) or (symbol == ' '):\n",
    "            new_word = True\n",
    "        else:\n",
    "            if (new_word):\n",
    "                tokens.append(symbol)\n",
    "            else:\n",
    "                tokens[-1] += symbol\n",
    "            new_word = False\n",
    "            \n",
    "    tokens_lower = [i.lower() for i in tokens]\n",
    "    filtered_tokens = [i for i in tokens_lower if (i not in stop_words)]\n",
    "    # -----------------\n",
    "    return filtered_tokens\n",
    "\n",
    "# применяем функцию в датафрейму с помощью метода .apply()\n",
    "tokenized_tweets= df.tweet_text.apply(tokenize_text)\n",
    "\n",
    "# добавляем новую колонку в исходный датафрейм\n",
    "df = df.assign(\n",
    "    tokenized=tokenized_tweets\n",
    ")\n",
    "\n",
    "\n",
    "df_tokenized = df.tokenized\n",
    "array_tokens = np.unique(df_tokenized)\n",
    "all_tokens = []\n",
    "for list_tokens in array_tokens:\n",
    "    for token in list_tokens:\n",
    "        all_tokens.append(token)\n",
    "        \n",
    "print(df_tokenized.head())        \n",
    "print(\"Количество уникальных токенов:\",len(set(all_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: поиск дубликатов в тексте\n",
    "\n",
    "Потренируйтесь в нахождении матрицы схожести для валидационного сета\n",
    "\n",
    "загрузите brand_tweets_valid.csv\n",
    "примените объект vectorizer, обученный на датасете brand_tweets.csv (просто скопируйте этот код из урока)\n",
    "примените функцию pairwise_distances к полученной матрице\n",
    "* Пользуясь матрицей схожести, полученной на предыдущем этапе, найдите top-5 твитов, похожих на твит валидационного сета с id=14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popup Apple Store crew has been giving out water to the people in line but they are in street clothes. No Apple logos anywhere yet. #SXSW\n",
      "-------------\n",
      "Apple employees just showed up in force to the #SXSW PopUp Apple Store. #iPad2\n",
      "-------------\n",
      "#sxsw apple store run out for the day :( boo apple.\n",
      "-------------\n",
      "video from the popup Apple store: {link} #sxsw #sxswi\n",
      "-------------\n",
      "#SXSW Apple Pop Up Store still has iPads in stock, we are waiting on line {link} via @mention #apple #ipad2‰Ыќ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "df_valid = pd.read_csv('data/brand_tweets_valid.csv', sep=',', encoding='utf8')\n",
    "# удаляем строки, в которых отсутствует текст твита\n",
    "df_valid.drop(df_valid[df_valid.tweet_text.isnull()].index, inplace=True)\n",
    "\n",
    "# -- ВАШ КОД ТУТ --\n",
    "# применяем функцию в датафрейму с помощью метода .apply()\n",
    "tokenized_tweets= df_valid.tweet_text.apply(tokenize_text)\n",
    "\n",
    "# добавляем новую колонку в исходный датафрейм\n",
    "df_valid = df_valid.assign(\n",
    "    tokenized=tokenized_tweets\n",
    ")\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_text)\n",
    "document_matrix = vectorizer.fit_transform(df_valid.tweet_text.values)\n",
    "source_tweet_index = 14\n",
    "tweet_distance = 1-pairwise_distances(document_matrix, metric=\"cosine\")\n",
    "sorted_similarity = np.argsort(-tweet_distance[source_tweet_index,:])\n",
    "\n",
    "print(df_valid.iloc[sorted_similarity[0]].tweet_text)\n",
    "print('-------------')\n",
    "print(df_valid.iloc[sorted_similarity[1]].tweet_text)\n",
    "print('-------------')\n",
    "print(df_valid.iloc[sorted_similarity[2]].tweet_text)\n",
    "print('-------------')\n",
    "print(df_valid.iloc[sorted_similarity[3]].tweet_text)\n",
    "print('-------------')\n",
    "print(df_valid.iloc[sorted_similarity[4]].tweet_text)\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас есть матрица схожести между объектами. Попробуйте решить задачу поиска дубликатов в тексте\n",
    "\n",
    "1. Визуализируйте гистограмму значений в матрице схожести\n",
    "1. Напишите функцию на Python, которая принимает индекс твита, пороговое значение (число от $0.0$ до $1.0$ и матрицу схожести, а затем выводит все твиты, схожесть которых больше, чем пороговое значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(8)    \n",
    "fig.set_figheight(8)\n",
    "ax.hist(tweet_distance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14     Popup Apple Store crew has been giving out wat...\n",
       "132    Apple employees just showed up in force to the...\n",
       "16     #sxsw apple store run out for the day :( boo a...\n",
       "163    video from the popup Apple store: {link} #sxsw...\n",
       "6      #SXSW Apple Pop Up Store still has iPads in st...\n",
       "341    Wanting in line at the unconfirmed Apple pop-u...\n",
       "65     141st in line for #ipad2 at #SXSW (@mention Ap...\n",
       "23     Cool! Apple to open temporary store at SXSW {l...\n",
       "226    Hehe RT‰ЫП@mention March 11. Austin, TX. Will ...\n",
       "72     Apple selling the new Terp2it album? RT @menti...\n",
       "357    Sitting on the ground waiting for my iPad at t...\n",
       "395    Crowley and Cashmore think iPad 2 is a minor s...\n",
       "62     First in line @mention #sxsw @mention store fo...\n",
       "319    RT@mention Crowley and Cashmore think iPad 2 i...\n",
       "63     10:30 AM line at Apple pop-up store in Austin....\n",
       "192    Hi, if came out here for #sxsw and in line at ...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similar_texts(tweet_index, threshold_value, tweet_distance):\n",
    "    tweet_index_raw = tweet_distance[tweet_index,:]\n",
    "    similarity_greater_threshold_value = np.where(tweet_index_raw>threshold_value)[0]\n",
    "    sorted_similarity = np.argsort(-tweet_distance[tweet_index,:])\n",
    "    \n",
    "    func = np.vectorize(lambda t: t in similarity_greater_threshold_value)\n",
    "    \n",
    "    sorted_similarity_greater_threshold_value = sorted_similarity[func(sorted_similarity)]\n",
    "    return sorted_similarity_greater_threshold_value\n",
    "\n",
    "indexes_most_similar_texts = similar_texts(14, 0.35, tweet_distance)\n",
    "similar_tweets = df_valid.iloc[indexes_most_similar_texts].tweet_text\n",
    "similar_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
